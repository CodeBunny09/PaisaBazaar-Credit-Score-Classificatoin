








# ğŸ“¦ Importing Required Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Suppress warnings
import warnings
warnings.filterwarnings("ignore")

# Display full column width and set float format
pd.set_option('display.max_columns', None)
pd.set_option('display.float_format', '{:.2f}'.format)





# Load the dataset
file_path = 'data/raw/dataset-2.csv'
df = pd.read_csv(file_path)

# Preview the first few rows
df.head()





# ğŸ§® Check dataset shape
print(f"Number of Rows: {df.shape[0]}")
print(f"Number of Columns: {df.shape[1]}")

# ğŸ” Check for duplicates
duplicate_rows = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_rows}")





# ğŸ§¾ Data type and non-null counts
df.info()





# ğŸ“Œ Check for real and disguised missing values
import numpy as np

# Convert all object-type columns to strings for safe processing
df_obj = df.select_dtypes(include='object')

# Check for known placeholders
placeholders = ['NA', 'N/A', 'null', 'NULL', '', ' ']
null_mask = df_obj.apply(lambda x: x.isin(placeholders)).sum()

# Regular null check
regular_nulls = df.isnull().sum()

# Combine and display
null_report = pd.DataFrame({
    'Regular_Nulls': regular_nulls,
    'Placeholder_Nulls': null_mask
})
null_report['Total_Nulls'] = null_report['Regular_Nulls'] + null_report['Placeholder_Nulls']
null_report = null_report[null_report['Total_Nulls'] > 0]
null_report





# ğŸ“Š Statistical overview of numerical columns
df.describe().T





# ğŸ¯ Unique values in each column
df.nunique().sort_values(ascending=False)





# ğŸ“‰ Check for missing/null values
df.isnull().sum().sort_values(ascending=False)





# ğŸ” Drop duplicates based on all columns
df_cleaned = df.drop_duplicates()

# ğŸ”¢ Check if duplicate IDs exist
print("Duplicate ID count:", df_cleaned.duplicated(subset='ID').sum())

# âœ… Confirm shape after cleaning
df_cleaned.shape





# Columns to drop
cols_to_drop = ['ID', 'Customer_ID', 'SSN', 'Name']

df_cleaned.drop(columns=cols_to_drop, inplace=True)

# âœ… Confirm shape
df_cleaned.shape





# Display column data types
df_cleaned.dtypes.value_counts()





# Show unique values (up to 10) for object-type columns
for col in df_cleaned.select_dtypes(include='object').columns:
    print(f"\nğŸ”¹ {col} â€” {df_cleaned[col].nunique()} unique values")
    print(df_cleaned[col].unique()[:10])





# Ordinal mapping for credit mix and score
ordinal_maps = {
    'Credit_Mix': {'Bad': 0, 'Standard': 1, 'Good': 2},
    'Credit_Score': {'Poor': 0, 'Standard': 1, 'Good': 2},
    'Payment_of_Min_Amount': {'No': 0, 'NM': 1, 'Yes': 2}
}

# Apply mappings
df_cleaned.replace(ordinal_maps, inplace=True)

# Confirm transformation
df_cleaned[['Credit_Mix', 'Credit_Score', 'Payment_of_Min_Amount']].head()





# One-hot encoding selected nominal columns
one_hot_cols = ['Occupation', 'Payment_Behaviour']
df_cleaned = pd.get_dummies(df_cleaned, columns=one_hot_cols, drop_first=True)

# Check shape and confirm new columns
print(f"âœ… Data shape after One-Hot Encoding: {df_cleaned.shape}")
df_cleaned.columns[-10:]  # Show last 10 columns to confirm encoding





from sklearn.preprocessing import MultiLabelBinarizer

# Convert comma-separated string to list
df_cleaned['Type_of_Loan'] = df_cleaned['Type_of_Loan'].apply(lambda x: [i.strip() for i in x.split(',')])

# Apply MultiLabelBinarizer
mlb = MultiLabelBinarizer()
loan_encoded = pd.DataFrame(mlb.fit_transform(df_cleaned['Type_of_Loan']), 
                            columns=['Loan_' + col for col in mlb.classes_])

# Concatenate and drop original column
df_cleaned = pd.concat([df_cleaned.drop('Type_of_Loan', axis=1), loan_encoded], axis=1)

# Check result
print(f"âœ… Shape after adding Loan columns: {df_cleaned.shape}")
loan_encoded.columns





# Create processed data directory if not exists
import os

processed_dir = "data/processed"
os.makedirs(processed_dir, exist_ok=True)

# Save as CSV
processed_path = os.path.join(processed_dir, "cleaned_dataset.csv")
df_cleaned.to_csv(processed_path, index=False)

print(f"âœ… Cleaned data saved to:\n{processed_path}")





# ğŸ“Š Chart 1: Distribution of Credit Scores

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
ax = sns.countplot(data=df, x='Credit_Score', palette='Set2')
plt.title('Distribution of Credit Scores', fontsize=14)
plt.xlabel('Credit Score Category')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis variables
print("X-axis (Categories):", df['Credit_Score'].unique())
print("Y-axis (Counts):", df['Credit_Score'].value_counts().to_dict())






# ğŸ“Š Chart 2: Age Distribution

plt.figure(figsize=(10, 6))
ax = sns.histplot(data=df, x='Age', bins=30, kde=True, color='skyblue')
plt.title('Distribution of Customer Age', fontsize=14)
plt.xlabel('Age')
plt.ylabel('Number of Customers')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis (Age Range):", f"{df['Age'].min()} to {df['Age'].max()}")
print("Y-axis: Count of customers in each age bin")





# ğŸ“Š Chart 3: Annual Income Distribution

plt.figure(figsize=(10, 6))
ax = sns.histplot(data=df, x='Annual_Income', bins=40, kde=True, color='orange')
plt.title('Distribution of Annual Income', fontsize=14)
plt.xlabel('Annual Income (in USD)')
plt.ylabel('Number of Customers')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis (Income Range):", f"{df['Annual_Income'].min():,.2f} to {df['Annual_Income'].max():,.2f}")
print("Y-axis: Count of customers in each income bin")





# ğŸ“Š Chart 4: Number of Loans by Credit Score Category

plt.figure(figsize=(9, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Num_of_Loan', palette='Set2')
plt.title('ğŸ“¦ Number of Loans vs Credit Score')
plt.xlabel('Credit Score')
plt.ylabel('Number of Loans')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Number of Loans per Customer (spread per credit group)")





# ğŸ“Š Chart 5: Credit Utilization Ratio vs Credit Score

plt.figure(figsize=(9, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Credit_Utilization_Ratio', palette='pastel')
plt.title('ğŸ“¦ Credit Utilization Ratio vs Credit Score')
plt.xlabel('Credit Score')
plt.ylabel('Credit Utilization Ratio (%)')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Credit Utilization Ratio (percentage per credit group)")





# ğŸ“Š Chart 6: Monthly Balance vs Credit Mix

plt.figure(figsize=(9, 6))
ax = sns.boxplot(data=df, x='Credit_Mix', y='Monthly_Balance', palette='Set2')
plt.title('ğŸ’° Monthly Balance vs Credit Mix')
plt.xlabel('Credit Mix Type')
plt.ylabel('Monthly Balance')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Mix'].unique())
print("Y-axis: Monthly Balance (Available Monthly Cash Flow)")





# ğŸ“Š Chart 7: Delay from Due Date vs Credit Score

plt.figure(figsize=(9, 6))
ax = sns.violinplot(data=df, x='Credit_Score', y='Delay_from_due_date', palette='pastel')
plt.title('â³ Payment Delay vs Credit Score')
plt.xlabel('Credit Score Category')
plt.ylabel('Delay from Due Date (Days)')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Delay from Due Date (in days)")





# ğŸ“Š Chart 8: Credit Inquiries vs Credit Score

plt.figure(figsize=(9, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Num_Credit_Inquiries', palette='coolwarm')
plt.title('ğŸ“‚ Credit Inquiries vs Credit Score')
plt.xlabel('Credit Score Category')
plt.ylabel('Number of Credit Inquiries')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Number of Credit Inquiries")





# ğŸ“Š Chart 9: Payment Behaviour Distribution

plt.figure(figsize=(12, 6))
ax = sns.countplot(data=df, x='Payment_Behaviour', order=df['Payment_Behaviour'].value_counts().index, palette='viridis')
plt.title('ğŸ’¸ Distribution of Payment Behaviour')
plt.xlabel('Payment Behaviour Type')
plt.ylabel('Number of Customers')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Payment_Behaviour'].unique())
print("Y-axis: Count of Customers per Payment Behaviour")





# ğŸ“Š Chart 10: Credit Score vs. Delayed Payments

plt.figure(figsize=(10, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Num_of_Delayed_Payment', palette='Set2')
plt.title('ğŸ“‰ Delayed Payments Across Credit Score Categories')
plt.xlabel('Credit Score')
plt.ylabel('Number of Delayed Payments')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Distribution of Delayed Payments for each Credit Score category")





# ğŸ“Š Chart 11: Credit History Age vs. Credit Score

plt.figure(figsize=(10, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Credit_History_Age', palette='Set3')
plt.title('ğŸ“˜ Credit History Age Distribution by Credit Score')
plt.xlabel('Credit Score')
plt.ylabel('Credit History Age (in months)')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Distribution of Credit History Age for each Credit Score category")





# ğŸ“Š Chart 12: Number of Credit Cards vs. Credit Score

plt.figure(figsize=(10, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Num_Credit_Card', palette='YlGnBu')
plt.title('ğŸ’³ Number of Credit Cards by Credit Score')
plt.xlabel('Credit Score')
plt.ylabel('Number of Credit Cards')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Distribution of Number of Credit Cards for each Credit Score category")





# ğŸ’° Chart 13: Monthly Investment vs. Credit Score

plt.figure(figsize=(10, 6))
ax = sns.boxplot(data=df, x='Credit_Score', y='Amount_invested_monthly', palette='Pastel1')
plt.title('ğŸ“ˆ Monthly Investment by Credit Score')
plt.xlabel('Credit Score')
plt.ylabel('Monthly Amount Invested')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# ğŸ” Output X & Y axis info
print("X-axis Categories:", df['Credit_Score'].unique())
print("Y-axis: Distribution of Amount Invested Monthly for each Credit Score category")





# ğŸ”¥ Chart 14: Correlation Heatmap

# Select only numeric columns
numeric_df = df.select_dtypes(include=['float64', 'int64'])

# Compute the correlation matrix
corr_matrix = numeric_df.corr()

plt.figure(figsize=(14, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, linewidths=0.5, cbar_kws={"shrink": 0.8})
plt.title('ğŸ”¥ Correlation Heatmap of Numerical Features')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X and Y axes show correlations between all numeric variables in the dataset")





# ğŸ§© Chart 15: Credit Mix vs Credit Score

plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Credit_Mix', hue='Credit_Score', palette='Set2')
plt.title('ğŸ§© Credit Mix vs Credit Score')
plt.xlabel('Credit Mix')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.legend(title='Credit Score')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X-axis: Credit_Mix (categories like Good, Standard, Bad)")
print("Y-axis: Count of customers")
print("Hue: Credit_Score (Good, Standard, Poor)")





# ğŸ’° Chart 16: Distribution of Monthly Balance by Credit Score

plt.figure(figsize=(10, 5))
sns.kdeplot(data=df, x='Monthly_Balance', hue='Credit_Score', fill=True, palette='Set1', alpha=0.6)
plt.title('ğŸ’° Distribution of Monthly Balance by Credit Score')
plt.xlabel('Monthly Balance')
plt.ylabel('Density')
plt.legend(title='Credit Score')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X-axis: Monthly_Balance (continuous variable in dollars)")
print("Y-axis: Density (distribution curve)")
print("Hue: Credit_Score (Good, Standard, Poor)")





# ğŸ§¾ Chart 17: Number of Loans vs Credit Score

plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x='Credit_Score', y='Num_of_Loan', palette='Set2')
plt.title('ğŸ§¾ Number of Loans vs Credit Score')
plt.xlabel('Credit Score')
plt.ylabel('Number of Loans')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X-axis: Credit_Score (categorical variable: Good, Standard, Poor)")
print("Y-axis: Num_of_Loan (number of different loan types a customer has)")





# ğŸ§¾ Chart 18: Credit Mix Distribution Across Credit Scores

plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Credit_Score', hue='Credit_Mix', palette='Set1')
plt.title('ğŸ§¾ Credit Mix Distribution Across Credit Scores')
plt.xlabel('Credit Score')
plt.ylabel('Count')
plt.legend(title='Credit Mix')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X-axis: Credit_Score (Good, Standard, Poor)")
print("Hue: Credit_Mix (Standard, Good, Bad)")
print("Y-axis: Number of Customers")





# ğŸ’° Chart 19: Annual Income vs Monthly In-hand Salary (Colored by Credit Score)

plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=df, 
    x='Annual_Income', 
    y='Monthly_Inhand_Salary', 
    hue='Credit_Score', 
    alpha=0.6,
    palette='Set2'
)
plt.title('ğŸ’° Annual Income vs Monthly In-hand Salary (Colored by Credit Score)')
plt.xlabel('Annual Income')
plt.ylabel('Monthly In-hand Salary')
plt.legend(title='Credit Score')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X-axis: Annual_Income")
print("Y-axis: Monthly_Inhand_Salary")
print("Hue: Credit_Score (Good, Standard, Poor)")





# ğŸ“Š Chart 20: Distribution of Number of Delayed Payments by Credit Score

plt.figure(figsize=(10, 6))
sns.histplot(
    data=df,
    x='Num_of_Delayed_Payment',
    hue='Credit_Score',
    bins=30,
    kde=True,
    palette='Set1',
    multiple='stack'
)
plt.title('ğŸ“Š Distribution of Number of Delayed Payments by Credit Score')
plt.xlabel('Number of Delayed Payments')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

# ğŸ” Output axis info
print("X-axis: Num_of_Delayed_Payment")
print("Y-axis: Count of Customers")
print("Hue: Credit_Score (Good, Standard, Poor)")











from scipy.stats import f_oneway

# Get income data by credit score class
income_good = df_cleaned[df_cleaned['Credit_Score'] == 2]['Annual_Income']
income_standard = df_cleaned[df_cleaned['Credit_Score'] == 1]['Annual_Income']
income_poor = df_cleaned[df_cleaned['Credit_Score'] == 0]['Annual_Income']

# Perform One-Way ANOVA
f_stat, p_val = f_oneway(income_good, income_standard, income_poor)

print("ğŸ“ˆ F-statistic:", round(f_stat, 4))
print("ğŸ“Š P-value:", round(p_val, 6))






from scipy.stats import chi2_contingency
import pandas as pd

# Bin credit card counts
df_cleaned['CreditCard_Bin'] = pd.cut(df_cleaned['Num_Credit_Card'], bins=[-1, 2, 5, 8, 12], labels=['Low', 'Moderate', 'High', 'Very High'])

# Create contingency table
contingency_table = pd.crosstab(df_cleaned['CreditCard_Bin'], df_cleaned['Credit_Score'])

# Run chi-square test
chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)

print("ğŸ”¢ Chi-Square Statistic:", round(chi2_stat, 4))
print("ğŸ“Š P-value:", round(p_val, 6))
print("ğŸ“ Degrees of Freedom:", dof)





# Get all columns related to occupation
occupation_columns = [col for col in df_cleaned.columns if col.startswith("Occupation_")]

# Reconstruct the original Occupation category
df_cleaned['Occupation'] = df_cleaned[occupation_columns].idxmax(axis=1).str.replace('Occupation_', '')

from scipy.stats import f_oneway

# Create groups for ANOVA test
groups = [df_cleaned[df_cleaned['Occupation'] == occ]['Delay_from_due_date'] for occ in df_cleaned['Occupation'].unique()]

# Run One-Way ANOVA
f_stat, p_val = f_oneway(*groups)

print("ğŸ“ˆ F-statistic:", round(f_stat, 4))
print("ğŸ“Š P-value:", round(p_val, 6))








# ğŸ“¦ Imports
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# ğŸ”½ Load cleaned data
df = pd.read_csv('data/processed/cleaned_dataset.csv')

# ğŸ·ï¸ Encode categorical features
categorical_cols = df.select_dtypes(include='object').columns.tolist()
print("Categorical columns to encode:", categorical_cols)

# ğŸ”„ Label Encoding (since all are ordinal/nominal, not high-cardinality text)
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# âœ… Split features and target
X = df.drop(columns=['Credit_Score'])  # ğŸ” Features
y = df['Credit_Score']                 # ğŸ¯ Target

# ğŸ”€ Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ” Show shape and sample
print("âœ… Shapes -> X_train:", X_train.shape, "X_test:", X_test.shape)
X_train.head()





from sklearn.preprocessing import StandardScaler

# ğŸ“Š Identify numeric columns
numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()
print("ğŸ§® Numeric columns to scale:", numeric_cols[:10], '...')

# ğŸ§¼ Apply standard scaling
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()
X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])

# âœ… Confirm scaling
X_train_scaled.head()





from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# âš™ï¸ Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
}

# ğŸ“Š Train and Evaluate
for name, model in models.items():
    print(f"\nğŸ“Œ Training: {name}")
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
    print("ğŸ“Š Classification Report:\n", classification_report(y_test, y_pred))
    print("ğŸ§© Confusion Matrix:\n", confusion_matrix(y_test, y_pred))





# ğŸ” Feature Importance Plot for XGBoost
import matplotlib.pyplot as plt
import seaborn as sns

# Refit XGBoost model just to extract feature importances
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_model.fit(X_train_scaled, y_train)

# Plot top 20 features
plt.figure(figsize=(12, 8))
importance = xgb_model.feature_importances_
features = X_train_scaled.columns

# Create a DataFrame for better sorting and plotting
feature_df = pd.DataFrame({'Feature': features, 'Importance': importance})
top_features = feature_df.sort_values(by='Importance', ascending=False).head(20)

sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')
plt.title('ğŸ“Œ Top 20 Important Features - XGBoost')
plt.tight_layout()
plt.show()

# ğŸ‘‡ Print variable names for reference
print("ğŸ” X-axis (Features):")
print(top_features['Feature'].tolist())
print("\nğŸŸ© Y-axis: Feature Importance Score")





from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier

# ğŸ›ï¸ Define parameters to tune
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [4, 6, 8],
    'learning_rate': [0.05, 0.1],
    'subsample': [0.8, 1],
    'colsample_bytree': [0.8, 1]
}

# âš™ï¸ Grid Search
xgb = XGBClassifier(eval_metric='mlogloss', random_state=42)
grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, 
                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)

grid_search.fit(X_train_scaled, y_train)

# ğŸ“Œ Best parameters and score
print("âœ… Best Parameters:", grid_search.best_params_)
print("ğŸ¯ Best Cross-Validation Accuracy:", grid_search.best_score_)






# âœ… Retrain final XGBoost with best params
final_xgb = XGBClassifier(
    learning_rate=0.1,
    max_depth=8,
    n_estimators=200,
    subsample=0.8,
    colsample_bytree=1,
    eval_metric='mlogloss',
    random_state=42
)

final_xgb.fit(X_train_scaled, y_train)
y_pred_final = final_xgb.predict(X_test_scaled)

# ğŸ“Š Evaluation
print("âœ… Final Accuracy:", accuracy_score(y_test, y_pred_final))
print("ğŸ“Š Classification Report:\n", classification_report(y_test, y_pred_final))
print("ğŸ§© Confusion Matrix:\n", confusion_matrix(y_test, y_pred_final))





from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score, roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# ğŸ¯ Binarize y_test for multi-class ROC AUC
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
y_score = final_xgb.predict_proba(X_test_scaled)
n_classes = y_test_bin.shape[1]

# ğŸ“¦ Initialize ROC containers
fpr = dict()
tpr = dict()
roc_auc = dict()
colors = cycle(['blue', 'red', 'green'])

# ğŸš€ Compute ROC curve and ROC area for each class
print("ğŸ“Š Class-wise ROC AUC Scores:")
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    print(f"ğŸ”¹ Class {i} - AUC: {roc_auc[i]:.4f}")

# ğŸŒ Compute micro and macro-average ROC AUC
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
print(f"ğŸ“‰ Micro-average AUC: {roc_auc['micro']:.4f}")

# Macro-average (unweighted)
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
mean_tpr = np.zeros_like(all_fpr)
for i in range(n_classes):
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
mean_tpr /= n_classes

fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])
print(f"ğŸ“ˆ Macro-average AUC: {roc_auc['macro']:.4f}")

# ğŸ¨ Plot ROC curves
plt.figure(figsize=(10, 7))
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f"Class {i} (AUC = {roc_auc[i]:.2f})")

plt.plot(fpr["micro"], tpr["micro"], label=f"Micro-Average (AUC = {roc_auc['micro']:.2f})", 
         color='deeppink', linestyle=':', linewidth=3)

plt.plot(fpr["macro"], tpr["macro"], label=f"Macro-Average (AUC = {roc_auc['macro']:.2f})", 
         color='navy', linestyle=':', linewidth=3)

plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ğŸ” ROC Curves for Final XGBoost Model (Multiclass)")
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()





from imblearn.over_sampling import SMOTE
from sklearn.pipeline import Pipeline

# âš™ï¸ Define SMOTE
smote = SMOTE(random_state=42)

# ğŸ” Resample training data
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

print(f"ğŸ§® Original Class Distribution:\n{y_train.value_counts()}")
print(f"\nğŸ“ˆ After SMOTE:\n{y_train_smote.value_counts()}")

# ğŸ” Retrain XGBoost on balanced data
xgb_smote = XGBClassifier(
    colsample_bytree=1,
    learning_rate=0.1,
    max_depth=8,
    n_estimators=200,
    subsample=0.8,
    random_state=42
)

print("\nğŸš€ Training XGBoost on SMOTE data...")
xgb_smote.fit(X_train_smote, y_train_smote)
y_pred_smote = xgb_smote.predict(X_test_scaled)

# ğŸ“Š Evaluation
print("âœ… Accuracy:", accuracy_score(y_test, y_pred_smote))
print("ğŸ“Š Classification Report:\n", classification_report(y_test, y_pred_smote))
print("ğŸ§© Confusion Matrix:\n", confusion_matrix(y_test, y_pred_smote))





from sklearn.utils.class_weight import compute_sample_weight

# ğŸ§® Compute class weights based on original labels
sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)

# â™»ï¸ Reinitialize the best XGBoost model
xgb_weighted = XGBClassifier(
    colsample_bytree=1,
    learning_rate=0.1,
    max_depth=8,
    n_estimators=200,
    subsample=0.8,
    random_state=42
)

# ğŸš€ Train with sample weights
print("ğŸš€ Training XGBoost with class weights...")
xgb_weighted.fit(X_train_scaled, y_train, sample_weight=sample_weights)

# ğŸ” Predict and evaluate
y_pred_weighted = xgb_weighted.predict(X_test_scaled)

print("âœ… Accuracy:", accuracy_score(y_test, y_pred_weighted))
print("ğŸ“Š Classification Report:\n", classification_report(y_test, y_pred_weighted))
print("ğŸ§© Confusion Matrix:\n", confusion_matrix(y_test, y_pred_weighted))





import joblib
import os

# ğŸ“ Ensure the models directory exists
os.makedirs("models", exist_ok=True)

# ğŸ’¾ Save the best model (XGBoost with class weights)
joblib.dump(xgb_weighted, "models/best_model.pkl")
print("âœ… Best model saved as 'models/best_model.pkl'")



